# -*- coding: utf-8 -*-
"""Question1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16HLgDkrkN0sgLM9LsrzA_4CGo_xJ46uB
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import tables

header_1 = "/content/drive/My Drive/MCA - Assignment 1/"
header_2 = "/content/drive/My Drive/IIITD Stuff/MCA - Assignment 1/"

img_path = os.path.join(header_1, "images")
query_path = os.path.join(header_1, "train/query")
ground_truth_path = os.path.join(header_1, "train/ground_truth")
data_path = os.path.join(header_1, "Shwetank's Code/models/cac_1")
query_output_path = os.path.join(header_1, "Shwetank's Code/queries/cac_1")

from PIL import Image, ImageOps, ImageFilter
import numpy as np
import pickle

imgs  = os.listdir(img_path)
imgs_base = [x.split('.')[0] for x in imgs]
print(str(len(imgs_base)) + " images received.")

count = 1
for node_name in imgs_base:
    print('processing file:' + str(count))
    count+=1
    img_file = node_name + ".jpg"

    im = Image.open(os.path.join(img_path, img_file))
    w, h = im.size
    ratio = min(100/w, 100/h)
    im = np.array(ImageOps.posterize(im.resize((int(w*ratio), int(h*ratio))), 2).filter(ImageFilter.SMOOTH))
    shape = im.shape

    I_c = [[] for i in range(64)]
    lambda_h = [[[[0 for i in range(64)] for j in range(shape[1])] for k in range(shape[0])] for l in range(11)]
    lambda_v = [[[[0 for i in range(64)] for j in range(shape[1])] for k in range(shape[0])] for l in range(11)]
    histogram = [0 for i in range(64)]

    for i in range(shape[0]):
        for j in range(shape[1]):
            color = int(im[i][j][0]/64) * 16 + int(im[i][j][1]/64) * 4 + int(im[i][j][2]/64)
            I_c[color].append([i, j])
            lambda_h[0][i][j][color] = 1
            lambda_v[0][i][j][color] = 1
            histogram[color] += 1
    for i in range(shape[0]):
        for j in range(shape[1]):
            color = int(im[i][j][0]/64) * 16 + int(im[i][j][1]/64) * 4 + int(im[i][j][2]/64)
            for k in range(1, 11):
                lambda_h[k][i][j][color] = lambda_h[k-1][i][j][color] + (lambda_h[0][i+k][j][color] if (i+k < shape[0]) else 0)
                lambda_v[k][i][j][color] = lambda_v[k-1][i][j][color] + (lambda_h[0][i][j+k][color] if (j+k < shape[1]) else 0)
    
    c_a_c = []
    dist = [1, 3, 5, 7]
    for i in dist:
        temp = [0 for a in range(64)]
        for j in range(64):
            for x, y in I_c[j]:
                if (y-i >= 0):
                    temp[j] += lambda_h[i][x][y-i][j]
                    if (x-i >= 0):
                        temp[j] += lambda_h[i][x-i][y-i][j]
                if (y+i < shape[1]):
                    temp[j] += lambda_h[i][x][y+i][j]
                    if (x-i >= 0):
                        temp[j] += lambda_h[i][x-i][y+i][j]
                if (x-i >= 0):
                    temp[j] += lambda_v[i-1][x-i][y][j]
                    if (y-i+1 >= 0):
                        temp[j] += lambda_v[i-1][x-i][y-i+1][j]
                if (x+i < shape[0]):
                    temp[j] += lambda_v[i-1][x+i][y][j]
                    if (y-i+1 >= 0):
                        temp[j] += lambda_v[i-1][x+i][y-i+1][j]
            if histogram[j] > 0:
                temp[j] /= (histogram[j] * i * 8)
        c_a_c += temp
    with open(os.path.join(data_path, (node_name + ".pkl")), "wb") as pkl_file:
        pickle.dump(c_a_c, pkl_file)
        pkl_file.close()

import pickle
import numpy as np
import time

qrys = os.listdir(query_path)
imgs = os.listdir(data_path)
qrys_base = [x.split('_query')[0] for x in qrys]
imgs_base = [x.split('.pkl')[0] for x in imgs]

timings = []

for qry in qrys_base:
    curr = time.time()
    qry_file = qry + "_query.txt"
    f = open(os.path.join(query_path, qry_file), "r")
    qry_string = f.readline()
    f.close()
    qry_img = qry_string.split(" ")[0].split("oxc1_")[1]
    f = open(os.path.join(data_path, (qry_img + ".pkl")), "rb")
    img_feature_pkl = pickle.load(f)
    f.close()
    ranking = {}
    count2 = 0
    for comp_img in imgs_base:
        if count2 % 100 == 0:
            print("queried with " + str(count2))
        count2 += 1
        f = open(os.path.join(data_path, (comp_img + ".pkl")), "rb")
        comp_feature_pkl = pickle.load(f)
        f.close()
        ranking[comp_img] = np.sum(np.abs(np.array(img_feature_pkl) - np.array(comp_feature_pkl)))
    sorted_ranking = {k: v for k, v in sorted(ranking.items(), key=lambda item: item[1])[:20]}
    timings.append(time.time() - curr)
    print(sorted_ranking)
    print("Took " + "{:.4f}".format(timings[-1]) + "seconds.")
    f = open(os.path.join(query_output_path, (qry_img + ".pkl")), "wb")
    pickle.dump(sorted_ranking, f)
    f.close()

import pickle
import numpy as np

qrys = os.listdir(query_path)
qrys_base = [x.split('_query')[0] for x in qrys]

precision = []
recall = []
f1_score = []
good_percent = []
ok_percent = []
junk_percent = []

for qry in qrys_base:
    qry_file = qry + "_query.txt"
    good_file = qry + "_good.txt"
    ok_file = qry + "_ok.txt"
    junk_file = qry + "_junk.txt"
    f = open(os.path.join(query_path, qry_file), "r")
    qry_string = f.readline()
    qry_img = qry_string.split(" ")[0].split("oxc1_")[1]
    f.close()
    f = open(os.path.join(query_output_path, (qry_img + ".pkl")), "rb")
    sorted_ranking = pickle.load(f)
    f.close()
    f = open(os.path.join(ground_truth_path, good_file), "r")
    good_results = [x.strip() for x in f.readlines()]
    f.close()
    f = open(os.path.join(ground_truth_path, ok_file), "r")
    ok_results = [x.strip() for x in f.readlines()] 
    f.close()
    f = open(os.path.join(ground_truth_path, junk_file), "r")
    junk_results = [x.strip() for x in f.readlines()] 
    f.close()
    gotten_result = list(sorted_ranking.keys())[1:]
    good_count = 0
    ok_count = 0
    junk_count = 0
    for result in gotten_result:
        if result in good_results:
            good_count += 1 
        if result in ok_results:
            ok_count += 1 
        if result in junk_results:
            junk_count += 1 
    p = (good_count + ok_count + junk_count) / len(gotten_result)
    r = (good_count + ok_count + junk_count) / (len(good_results) + len(ok_results) + len(junk_results))
    f1 = (2 * p * r) / (p + r) if p + r > 0 else 0
    gd_pc = good_count / len(good_results)
    ok_pc = good_count / len(ok_results)
    jnk_pc = good_count / len(junk_results)
    precision.append(p)
    recall.append(r)
    f1_score.append(f1)
    good_percent.append(gd_pc)
    ok_percent.append(ok_pc)
    junk_percent.append(jnk_pc)
print("\t\tPrecision\tRecall\t\tF1 Score")
print("Maximum\t\t" + "{:.4f}".format(max(precision)) + "\t\t" + "{:.4f}".format(max(recall)) + "\t\t" + "{:.4f}".format(max(f1_score)))
print("Minimum\t\t" + "{:.4f}".format(min(precision)) + "\t\t" + "{:.4f}".format(min(recall)) + "\t\t" + "{:.4f}".format(min(f1_score)))
print("Average\t\t" + "{:.4f}".format(sum(precision) / len(precision)) + "\t\t" + "{:.4f}".format(sum(recall) / len(recall)) + "\t\t" + "{:.4f}".format(sum(f1_score) / len(f1_score)))
print()
print("Average percentage of good queries retrieved\t" + "{:.4f}".format(sum(good_percent) / len(good_percent)))
print("Average percentage of ok queries retrieved\t" + "{:.4f}".format(sum(ok_percent) / len(ok_percent)))
print("Average percentage of junk queries retrieved\t" + "{:.4f}".format(sum(junk_percent) / len(junk_percent)))
print()
print("Average retrieval time\t" + "{:.4f}".format(sum(timings) / len(timings)))